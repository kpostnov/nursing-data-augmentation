import os
import random
import numpy as np
from sklearn.utils import shuffle
import utils.settings as settings
from tensorflow.keras.utils import to_categorical

import warnings
warnings.filterwarnings("ignore")


def get_activity_from_file_path(file_path: str) -> int:
    # Get file name from file path
    file_name = os.path.basename(file_path)
    # Get activity from file name
    activity = int(file_name.split('_')[2])

    return activity


def chunk_generator(synth_files: list):
    """
    Takes a list of .npy files as inputs and yields chunks that (should) fit into memory.
    Chunks are being generated by taking 1/10 of each numpy file randomly and combining them into one chunk.
    We use the file_slice_map so that we don't always yield the first tenths of each file, then the second and so on.
    We want to randomly pick a part and keep track of which parts we already used.
    """

    # Initialize dictionary that maps each .npy to its parts (tenths) that haven't been yielded yet
    file_tenths_map = {file: [i for i in range(10)] for file in synth_files}
   
    for i in range(10):
        print(f'Chunk: {i} / 10')

        X_chunk = None
        y_chunk = None

        for index, file in enumerate(synth_files):
            # Get the tenths that haven't been yielded yet
            random_tenth = random.choice(file_tenths_map[file])

            # Get length of numpy data in order to determine 1/10 
            gen_data_size = np.load(file).shape[0]
            gen_data_chunk_size = gen_data_size // 10
            # Load 1/10 of numpy data
            chunk = np.load(file, mmap_mode='r')[random_tenth * gen_data_chunk_size : (random_tenth+1) * gen_data_chunk_size].copy()

            # Remove used tenths from list
            file_tenths_map[file].remove(random_tenth)

            # Create y from file name
            activity = get_activity_from_file_path(file)
            # One hot encode activity
            activity_one_hot_encoded = to_categorical(np.array(activity), num_classes=len(settings.LABELS))
            activity_chunk = np.tile(activity_one_hot_encoded, (chunk.shape[0], 1))

            # Append to X_train and y_train
            if index == 0:
                X_chunk = chunk
                y_chunk = activity_chunk
            else:
                X_chunk = np.append(X_chunk, chunk, axis=0)
                y_chunk = np.append(y_chunk, activity_chunk, axis=0)
        
        # Shuffle X_chunk and y_chunk
        if len(synth_files) != 0: 
            X_chunk, y_chunk = shuffle(X_chunk, y_chunk)

        yield X_chunk, y_chunk
